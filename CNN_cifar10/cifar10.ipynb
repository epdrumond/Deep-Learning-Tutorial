{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uu6zjKQc6Gn",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we are going to develop a simple CNN for the categorization of images using the CIFAR-10 dataset. This project is part of the assignments of the Neural Networks and Deep Learning Tutorial (found [here](https://www.udemy.com/deep-learning-com-python-az-curso-completo/learn/practice/1043276/introduction#overview))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xvfcd4udgC9",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm5GsK4uc3fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Basic imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#SkLearn imports\n",
        "\n",
        "\n",
        "#Keras imports\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OrqbvVXdx7q",
        "colab_type": "text"
      },
      "source": [
        "# Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdN7Zm8JdyRd",
        "colab_type": "code",
        "outputId": "7c2ac248-5113-40be-f50a-1ea5c50c6deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcgAgwPCd-Aa",
        "colab_type": "code",
        "outputId": "0bc36aaa-211c-4b3a-f47f-34b5360cc15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "#Print single image\n",
        "plt.figure(figsize = (2,2))\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc949b0c828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPKoxoSyeSSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize features\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmFGwyVffC7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encode target\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jti7r88ggTf7",
        "colab_type": "code",
        "outputId": "2131498b-4d7b-4e98-9440-9f0d073565e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7JV45BTfkSL",
        "colab_type": "text"
      },
      "source": [
        "# Classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em2OAYoAiKQ0",
        "colab_type": "text"
      },
      "source": [
        "## Create CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmfXNT9kfho9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define CNN as function\n",
        "def create_model(n_pre, n_filters, input_dim, n_dense, n_nodes, drop, n_out):\n",
        "  model = Sequential()\n",
        "  \n",
        "  #Preprocessing layers\n",
        "  for i in range(n_pre):\n",
        "    if i == 0:\n",
        "      model.add(Conv2D(filters = n_filters, \n",
        "                kernel_size = (3,3), \n",
        "                strides = (1,1),\n",
        "                input_shape = (input_dim[0],input_dim[1],input_dim[2]),\n",
        "                activation = 'relu'))\n",
        "    else:\n",
        "      model.add(Conv2D(filters = n_filters, \n",
        "                kernel_size = (3,3), \n",
        "                strides = (1,1),\n",
        "                activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  #Dense layers\n",
        "  for i in range(n_dense - 1):\n",
        "    model.add(Dense(units = n_nodes, activation = 'relu'))\n",
        "    model.add(Dropout(drop))\n",
        "  model.add(Dense(units = n_out, activation = 'softmax'))\n",
        "  \n",
        "  #Compilation\n",
        "  model.compile(loss = 'categorical_crossentropy', \n",
        "                optimizer = 'adam',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BLPulA6hX_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create model instance\n",
        "model = create_model(n_pre = 2,\n",
        "                     n_filters = 64,\n",
        "                     input_dim = x_train.shape[1:],\n",
        "                     n_dense = 2,\n",
        "                     n_nodes = 256,\n",
        "                     drop = 0.3,\n",
        "                     n_out = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKJAPHiBiQvv",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOUrKkvBiDW5",
        "colab_type": "code",
        "outputId": "57b13abe-97b6-442b-caf1-2248927764e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x = x_train,\n",
        "          y = y_train,\n",
        "          epochs = 50,\n",
        "          batch_size = 128,\n",
        "          validation_data = (x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5300 - acc: 0.8137 - val_loss: 1.0221 - val_acc: 0.6659\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 0.4519 - acc: 0.8397 - val_loss: 0.9069 - val_acc: 0.7253\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 0.3859 - acc: 0.8642 - val_loss: 0.9699 - val_acc: 0.7234\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.3378 - acc: 0.8826 - val_loss: 0.8706 - val_acc: 0.7258\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 0.2876 - acc: 0.8994 - val_loss: 1.0294 - val_acc: 0.6935\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 0.2571 - acc: 0.9089 - val_loss: 1.0167 - val_acc: 0.7185\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 0.2309 - acc: 0.9174 - val_loss: 1.0663 - val_acc: 0.7115\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 0.2182 - acc: 0.9236 - val_loss: 1.0768 - val_acc: 0.7198\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 0.1922 - acc: 0.9314 - val_loss: 1.0693 - val_acc: 0.7254\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.1832 - acc: 0.9367 - val_loss: 1.1639 - val_acc: 0.7257\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 0.1740 - acc: 0.9396 - val_loss: 1.5632 - val_acc: 0.7195\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 0.1621 - acc: 0.9431 - val_loss: 1.2537 - val_acc: 0.6802\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.1522 - acc: 0.9460 - val_loss: 1.1583 - val_acc: 0.7053\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.1432 - acc: 0.9507 - val_loss: 1.1950 - val_acc: 0.7232\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.1366 - acc: 0.9524 - val_loss: 1.5159 - val_acc: 0.7254\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.1403 - acc: 0.9518 - val_loss: 1.3267 - val_acc: 0.7100\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.1326 - acc: 0.9537 - val_loss: 1.3160 - val_acc: 0.7199\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.1210 - acc: 0.9576 - val_loss: 1.7395 - val_acc: 0.7093\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.1303 - acc: 0.9546 - val_loss: 1.4376 - val_acc: 0.6845\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.1223 - acc: 0.9582 - val_loss: 1.6641 - val_acc: 0.6935\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.1193 - acc: 0.9590 - val_loss: 1.4119 - val_acc: 0.7426\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.1074 - acc: 0.9629 - val_loss: 1.3676 - val_acc: 0.7320\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.1059 - acc: 0.9640 - val_loss: 1.3528 - val_acc: 0.7204\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.1081 - acc: 0.9629 - val_loss: 1.7819 - val_acc: 0.7087\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.1008 - acc: 0.9659 - val_loss: 1.4379 - val_acc: 0.7147\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.1030 - acc: 0.9647 - val_loss: 1.4746 - val_acc: 0.7376\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.1021 - acc: 0.9645 - val_loss: 1.5592 - val_acc: 0.7243\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 0.0922 - acc: 0.9679 - val_loss: 1.6659 - val_acc: 0.6911\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.0930 - acc: 0.9679 - val_loss: 1.8203 - val_acc: 0.6859\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.0905 - acc: 0.9685 - val_loss: 1.7071 - val_acc: 0.7058\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.0919 - acc: 0.9688 - val_loss: 1.5467 - val_acc: 0.7195\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.0912 - acc: 0.9684 - val_loss: 2.0036 - val_acc: 0.6805\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 0.0884 - acc: 0.9702 - val_loss: 1.4829 - val_acc: 0.7392\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 0.0816 - acc: 0.9724 - val_loss: 1.7632 - val_acc: 0.7018\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 0.0830 - acc: 0.9714 - val_loss: 1.7553 - val_acc: 0.7207\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.0834 - acc: 0.9719 - val_loss: 1.5291 - val_acc: 0.7166\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.0845 - acc: 0.9710 - val_loss: 1.6177 - val_acc: 0.7181\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0745 - acc: 0.9743 - val_loss: 1.4147 - val_acc: 0.6676\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0747 - acc: 0.9745 - val_loss: 1.5302 - val_acc: 0.7345\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0726 - acc: 0.9745 - val_loss: 1.5777 - val_acc: 0.7231\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0754 - acc: 0.9745 - val_loss: 1.7164 - val_acc: 0.7318\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0721 - acc: 0.9764 - val_loss: 1.6559 - val_acc: 0.7306\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0749 - acc: 0.9746 - val_loss: 1.7810 - val_acc: 0.7215\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.0724 - acc: 0.9753 - val_loss: 1.4935 - val_acc: 0.7304\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.0715 - acc: 0.9759 - val_loss: 1.6187 - val_acc: 0.7335\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.0642 - acc: 0.9787 - val_loss: 1.4505 - val_acc: 0.7320\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.0637 - acc: 0.9785 - val_loss: 1.6053 - val_acc: 0.7240\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.0652 - acc: 0.9777 - val_loss: 1.6862 - val_acc: 0.6721\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 0.0739 - acc: 0.9752 - val_loss: 1.5299 - val_acc: 0.7268\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 0.0676 - acc: 0.9773 - val_loss: 1.6429 - val_acc: 0.7019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8f6be07f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEfAGhL0m7K2",
        "colab_type": "text"
      },
      "source": [
        "# Train augmented model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZAVIPI7rFHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate new instancies \n",
        "x_new_train = ImageDataGenerator(rotation_range = 7,\n",
        "                                 horizontal_flip = True,\n",
        "                                 shear_range = 0.2,\n",
        "                                 height_shift_range = 0.07,\n",
        "                                 zoom_range = 0.2)\n",
        "x_new_test = ImageDataGenerator()\n",
        "\n",
        "aug_train = x_new_train.flow(x_train, y_train, batch_size = 128)\n",
        "aug_test = x_new_test.flow(x_train, y_train, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4fxgUUCrKum",
        "colab_type": "code",
        "outputId": "6906c346-3175-472b-f37d-6ec3141f153a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "aug_model = create_model(n_pre = 2,\n",
        "                     n_filters = 64,\n",
        "                     input_dim = x_train.shape[1:],\n",
        "                     n_dense = 2,\n",
        "                     n_nodes = 256,\n",
        "                     drop = 0.3,\n",
        "                     n_out = 10)\n",
        "\n",
        "aug_model.fit_generator(aug_train, \n",
        "                        steps_per_epoch = 60000 / 128, \n",
        "                        epochs = 50,\n",
        "                        validation_data =  aug_test,\n",
        "                        validation_steps = 60000 / 128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/468 [==============================] - 48s 102ms/step - loss: 1.5155 - acc: 0.4707 - val_loss: 1.3858 - val_acc: 0.4985\n",
            "Epoch 2/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 1.1791 - acc: 0.5846 - val_loss: 1.3449 - val_acc: 0.5675\n",
            "Epoch 3/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 1.0514 - acc: 0.6353 - val_loss: 1.1433 - val_acc: 0.6348\n",
            "Epoch 4/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.9663 - acc: 0.6631 - val_loss: 0.7976 - val_acc: 0.7226\n",
            "Epoch 5/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.8988 - acc: 0.6879 - val_loss: 0.8308 - val_acc: 0.7149\n",
            "Epoch 6/50\n",
            "469/468 [==============================] - 44s 95ms/step - loss: 0.8507 - acc: 0.7047 - val_loss: 0.7974 - val_acc: 0.7305\n",
            "Epoch 7/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.8127 - acc: 0.7181 - val_loss: 0.7938 - val_acc: 0.7289\n",
            "Epoch 8/50\n",
            "469/468 [==============================] - 45s 96ms/step - loss: 0.7895 - acc: 0.7248 - val_loss: 0.7723 - val_acc: 0.7350\n",
            "Epoch 9/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.7603 - acc: 0.7371 - val_loss: 0.7925 - val_acc: 0.7249\n",
            "Epoch 10/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.7348 - acc: 0.7448 - val_loss: 0.6573 - val_acc: 0.7702\n",
            "Epoch 11/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.7101 - acc: 0.7538 - val_loss: 0.6072 - val_acc: 0.7911\n",
            "Epoch 12/50\n",
            "469/468 [==============================] - 44s 93ms/step - loss: 0.6960 - acc: 0.7590 - val_loss: 0.5717 - val_acc: 0.8008\n",
            "Epoch 13/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6784 - acc: 0.7643 - val_loss: 0.5671 - val_acc: 0.8019\n",
            "Epoch 14/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6657 - acc: 0.7685 - val_loss: 0.5266 - val_acc: 0.8152\n",
            "Epoch 15/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6469 - acc: 0.7744 - val_loss: 0.6497 - val_acc: 0.7716\n",
            "Epoch 16/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6344 - acc: 0.7806 - val_loss: 0.6633 - val_acc: 0.7866\n",
            "Epoch 17/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6223 - acc: 0.7828 - val_loss: 0.4516 - val_acc: 0.8439\n",
            "Epoch 18/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6102 - acc: 0.7896 - val_loss: 0.6350 - val_acc: 0.7835\n",
            "Epoch 19/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.6007 - acc: 0.7898 - val_loss: 0.6162 - val_acc: 0.7857\n",
            "Epoch 20/50\n",
            "469/468 [==============================] - 45s 96ms/step - loss: 0.5906 - acc: 0.7953 - val_loss: 0.5866 - val_acc: 0.8045\n",
            "Epoch 21/50\n",
            "469/468 [==============================] - 45s 97ms/step - loss: 0.5720 - acc: 0.8012 - val_loss: 0.5016 - val_acc: 0.8238\n",
            "Epoch 22/50\n",
            "469/468 [==============================] - 45s 97ms/step - loss: 0.5638 - acc: 0.8041 - val_loss: 0.5262 - val_acc: 0.8159\n",
            "Epoch 23/50\n",
            "469/468 [==============================] - 45s 96ms/step - loss: 0.5602 - acc: 0.8033 - val_loss: 0.4653 - val_acc: 0.8402\n",
            "Epoch 24/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.5472 - acc: 0.8089 - val_loss: 0.7485 - val_acc: 0.7738\n",
            "Epoch 25/50\n",
            "469/468 [==============================] - 45s 96ms/step - loss: 0.5476 - acc: 0.8109 - val_loss: 0.4004 - val_acc: 0.8641\n",
            "Epoch 26/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.5340 - acc: 0.8143 - val_loss: 0.4445 - val_acc: 0.8503\n",
            "Epoch 27/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.5239 - acc: 0.8185 - val_loss: 0.4240 - val_acc: 0.8566\n",
            "Epoch 28/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.5163 - acc: 0.8195 - val_loss: 0.4672 - val_acc: 0.8345\n",
            "Epoch 29/50\n",
            "469/468 [==============================] - 44s 95ms/step - loss: 0.5190 - acc: 0.8194 - val_loss: 0.3483 - val_acc: 0.8819\n",
            "Epoch 30/50\n",
            "469/468 [==============================] - 44s 95ms/step - loss: 0.5103 - acc: 0.8207 - val_loss: 0.3807 - val_acc: 0.8662\n",
            "Epoch 31/50\n",
            "469/468 [==============================] - 44s 95ms/step - loss: 0.5013 - acc: 0.8255 - val_loss: 0.4603 - val_acc: 0.8461\n",
            "Epoch 32/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.4981 - acc: 0.8270 - val_loss: 0.3614 - val_acc: 0.8765\n",
            "Epoch 33/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4905 - acc: 0.8290 - val_loss: 0.3076 - val_acc: 0.8956\n",
            "Epoch 34/50\n",
            "469/468 [==============================] - 44s 95ms/step - loss: 0.4861 - acc: 0.8305 - val_loss: 0.3831 - val_acc: 0.8677\n",
            "Epoch 35/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4789 - acc: 0.8336 - val_loss: 0.3245 - val_acc: 0.8888\n",
            "Epoch 36/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4708 - acc: 0.8366 - val_loss: 0.3293 - val_acc: 0.8888\n",
            "Epoch 37/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4622 - acc: 0.8378 - val_loss: 0.3176 - val_acc: 0.8915\n",
            "Epoch 38/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4602 - acc: 0.8375 - val_loss: 0.3240 - val_acc: 0.8905\n",
            "Epoch 39/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4609 - acc: 0.8386 - val_loss: 0.2817 - val_acc: 0.9051\n",
            "Epoch 40/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4587 - acc: 0.8406 - val_loss: 0.3154 - val_acc: 0.8943\n",
            "Epoch 41/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4496 - acc: 0.8438 - val_loss: 0.2912 - val_acc: 0.9021\n",
            "Epoch 42/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4507 - acc: 0.8421 - val_loss: 0.3860 - val_acc: 0.8691\n",
            "Epoch 43/50\n",
            "469/468 [==============================] - 44s 94ms/step - loss: 0.4435 - acc: 0.8457 - val_loss: 0.3232 - val_acc: 0.8906\n",
            "Epoch 44/50\n",
            "469/468 [==============================] - 45s 96ms/step - loss: 0.4379 - acc: 0.8477 - val_loss: 0.2796 - val_acc: 0.9060\n",
            "Epoch 45/50\n",
            "469/468 [==============================] - 45s 96ms/step - loss: 0.4362 - acc: 0.8483 - val_loss: 0.3695 - val_acc: 0.8753\n",
            "Epoch 46/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.4343 - acc: 0.8477 - val_loss: 0.2927 - val_acc: 0.9007\n",
            "Epoch 47/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.4295 - acc: 0.8520 - val_loss: 0.3757 - val_acc: 0.8665\n",
            "Epoch 48/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.4235 - acc: 0.8523 - val_loss: 0.2719 - val_acc: 0.9091\n",
            "Epoch 49/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.4242 - acc: 0.8503 - val_loss: 0.3542 - val_acc: 0.8769\n",
            "Epoch 50/50\n",
            "469/468 [==============================] - 45s 95ms/step - loss: 0.4207 - acc: 0.8531 - val_loss: 0.2448 - val_acc: 0.9167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8f65b6278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}